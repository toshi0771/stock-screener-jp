# 0銘柄検出問題の根本原因分析

**作成日:** 2026年1月27日  
**対象:** 200日新高値押し目スクリーニング  
**症状:** データ取得成功率0.0%、検出0銘柄

---

## 📅 実行環境の確認

### 正しい情報

- **実行日:** 2026年1月26日（月曜日・営業日）
- **契約日確定:** 2026-01-26（正しい）
- **キャッシュサイズ:** 55MB（57,828,125 B）
- **処理時間:** 2時間6分23秒
- **メモリ使用量:** 103.03MB

### 日付範囲の計算

```python
end_date = 2026-01-26
lookback_days = 300
start_date = 2026-01-26 - 300日 = 2025-04-01
```

**つまり:**
- start_date: 20250401
- end_date: 20260126
- 期間: 2025年4月1日 ～ 2026年1月26日（300暦日）

---

## 🔍 根本原因の仮説

### 仮説1: キャッシュデータが2025年4月1日より新しい

**可能性:**
- キャッシュに保存されているデータの最古日が2025年4月1日より新しい
- 例: 最古日が2025年5月1日の場合、`df['Date'] >= 2025-04-01`でフィルタリングしても、実際には2025年5月1日以降のデータしか返されない
- その結果、200日分のデータが不足する（`len(df) < 200`で除外）

**検証方法:**
- キャッシュファイルを直接読み込んで、Date列の範囲を確認
- デバッグログで`df['Date'].min()`を出力

### 仮説2: キャッシュの最終更新日が古すぎる

**可能性:**
- `max_age_days=30`のチェックで除外されている
- キャッシュの最終更新日が2025年12月27日以前の場合、期限切れと判定される

**検証方法:**
- デバッグログで`last_date`と`age.days`を確認

### 仮説3: Date列のデータ型の問題

**可能性:**
- キャッシュに保存されているDate列が文字列型
- `pd.to_datetime(df['Date'])`で変換時にエラーが発生
- または、変換後の日付フォーマットが異なる

**検証方法:**
- デバッグログで`df['Date'].dtype`を出力
- 変換前後のDate列を確認

### 仮説4: キャッシュファイルが空または破損

**可能性:**
- キャッシュファイルは存在するが、中身が空
- または、pickleファイルが破損している

**検証方法:**
- `_load_cache_data()`の戻り値を確認
- `len(df)`が0の場合、空のDataFrameが返されている

---

## 🐛 最も可能性の高い原因

### **原因: キャッシュデータの開始日が2025年4月1日より新しい**

**理由:**

1. **GitHub Actionsのキャッシュ保存期間**
   - GitHub Actionsのキャッシュは7日間で削除される
   - しかし、永続キャッシュは`~/.cache/stock_prices`に保存されている
   - これは`actions/cache@v4`で復元されるため、最大7日間の古さまで許容される

2. **キャッシュの差分更新**
   - `persistent_cache.set()`はマージ処理を行う
   - しかし、新規データのみを追加するため、古いデータは削除されない
   - つまり、キャッシュには最新300日分のデータしか保存されていない可能性

3. **300日前のデータが存在しない**
   - 2025年4月1日のデータがキャッシュに存在しない
   - 実際のキャッシュの最古日は2025年5月1日頃（推定）
   - その結果、`df['Date'] >= 2025-04-01`でフィルタリングしても、実際には2025年5月1日以降のデータしか返されない
   - 200日分のデータが不足する（約180日分しかない）

4. **`len(df) < 200`で除外**
   - 200日分のデータがないため、すべての銘柄が除外される
   - データ取得成功率0.0%

---

## 🔧 修正案

### 修正1: lookback_daysを増やす

**変更前:**
```python
start_str, end_str = get_date_range_for_screening(end_date, 300)
```

**変更後:**
```python
# 営業日ベースで300日分を確保するため、暦日で450日分取得
start_str, end_str = get_date_range_for_screening(end_date, 450)
```

**効果:**
- 2026-01-26 - 450日 = 2024-10-03
- キャッシュに2024年10月以降のデータがあれば、200日分のデータを確保できる

### 修正2: データ不足時にAPIから取得

**変更前:**
```python
if df is None or len(df) < 200:
    return None
```

**変更後:**
```python
if df is None or len(df) < 200:
    # キャッシュが不足している場合、APIから追加取得
    logger.warning(f"キャッシュデータ不足: {code} ({len(df) if df is not None else 0}行)")
    
    # より長い期間で再取得
    start_str_extended, _ = get_date_range_for_screening(end_date, 450)
    df = await self.cache.get_or_fetch(
        code, start_str_extended, end_str,
        self.jq_client.get_prices_daily_quotes,
        session, code, start_str_extended, end_str
    )
    
    if df is not None:
        await self.persistent_cache.set(code, start_str_extended, end_str, df)
    
    if df is None or len(df) < 200:
        return None
```

### 修正3: max_age_daysを延長

**変更前:**
```python
df = await self.persistent_cache.get(code, start_str, end_str)
```

**変更後:**
```python
# キャッシュの有効期限を60日に延長
df = await self.persistent_cache.get(code, start_str, end_str, max_age_days=60)
```

**効果:**
- 2ヶ月前のキャッシュまで有効になる
- ただし、データが古すぎる可能性もあるため注意

### 修正4: デバッグログの追加（実装済み）

**追加したログ:**
- キャッシュ取得開始
- キャッシュファイル存在確認
- キャッシュデータの行数と最終日
- Date列の範囲
- フィルタリング結果（第1・第2フィルター）
- キャッシュミス時の詳細情報

---

## 📊 検証計画

### ステップ1: デバッグログの確認

1. GitHub Actionsで再実行
2. ログから以下を確認:
   - キャッシュファイルの存在
   - キャッシュデータの行数と最終日
   - Date列の範囲（最古日・最新日）
   - フィルタリング結果（第1・第2フィルター）
   - キャッシュミスの理由

### ステップ2: 修正の実装

1. 仮説が正しければ、lookback_daysを450に増やす
2. または、データ不足時にAPIから追加取得する処理を追加

### ステップ3: 再テスト

1. 修正後に再実行
2. データ取得成功率が向上するか確認
3. 検出銘柄数が0より大きくなるか確認

---

## ⏱️ タイムアウト時間の確認

### ワークフローファイルの確認

**ファイル:** `.github/workflows/screening-200day-pullback.yml`

**確認事項:**
- `timeout-minutes`の設定値
- ユーザーによると6時間（360分）

---

## 📝 結論

**最も可能性の高い根本原因:**

> **キャッシュデータの開始日が2025年4月1日より新しいため、300日分のデータを取得できず、`len(df) < 200`で全銘柄が除外されている**

**対策:**

1. **即座に実施:** デバッグログを追加して、実際のキャッシュデータの範囲を確認
2. **仮説が正しければ:** lookback_daysを450に増やす、またはデータ不足時にAPIから追加取得
3. **長期的対策:** キャッシュの保存期間を延長、または定期的に古いデータを削除

**次のアクション:**

1. ✅ デバッグログを追加（完了）
2. ⏳ GitHub Actionsで再実行してログを確認
3. ⏳ 仮説を検証
4. ⏳ 修正を実装
5. ⏳ 再テスト
